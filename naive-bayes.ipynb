{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive-Bayes Model\n",
    "This notebook creates a naive-bayes model and executes it on sample text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBayesClass:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.probas = None\n",
    "        self.predict = None\n",
    "        \n",
    "    def calc_probas(self, features, targets):\n",
    "        \n",
    "        # combine features and targets into single dataframe\n",
    "        df = features\n",
    "        df['class_labels'] = targets\n",
    "        # feature counts by class\n",
    "        freq = df.groupby(df.columns[-1]).sum()\n",
    "        # total count of features in sample (to add for smoothing of zero values)\n",
    "        tot_num = len(freq.columns)\n",
    "        # calc totals per class\n",
    "        freq['class_total'] = freq.sum(axis=1) + tot_num\n",
    "        # calc probabilities of each feature appearing in each class\n",
    "        self.probas = (freq.iloc[:, 0:-1] + 1).div(freq['class_total'], axis=0)\n",
    "        return(self.probas)\n",
    "    \n",
    "    def predict_class(self, features):\n",
    "        \n",
    "        def process(feat_vals):\n",
    "            \n",
    "            # remove features not in training set\n",
    "            feat_trn = set(feat_vals).intersection(self.probas.columns)\n",
    "            # calc probabilities of feature per class\n",
    "            predict_probas = self.probas[list(feat_trn)].prod(axis=1)\n",
    "            # return predicted class\n",
    "            return(predict_probas.idxmax(axis=1))\n",
    "        \n",
    "        self.predict = features.apply(lambda x: process(x))\n",
    "        return(self.predict)\n",
    "    \n",
    "    def metrics(self, actual):\n",
    "\n",
    "        # cacluate overall accuracy\n",
    "        accuracy = sum(self.predict == actual) / len(self.predict)\n",
    "        \n",
    "        classes = self.predict.append(actual).unique()\n",
    "    \n",
    "        df_prec_rec = pd.DataFrame(index=['TP', 'FP', 'FN', 'precision', 'recall'])\n",
    "    \n",
    "        # cacluate true positives, false positives and false negatives for each class\n",
    "        for cls in classes:\n",
    "            TP = sum((self.predict == cls) & (self.predict == actual))\n",
    "            FP = sum((self.predict == cls) & (self.predict != actual) & (actual != cls))\n",
    "            FN = sum((self.predict != cls) & (self.predict != actual) & (actual == cls))\n",
    "            precision = TP / (TP + FP)\n",
    "            recall = TP / (TP + FN)\n",
    "            df_prec_rec[cls] = [TP, FP, FN, precision, recall]\n",
    "        \n",
    "        precision = df_prec_rec.loc['precision', :].mean()\n",
    "        recall = df_prec_rec.loc['recall', :].mean()\n",
    "        \n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {'text': \n",
    "             [\"a great game\", \"the election was over\", \"very clean match\", \n",
    "              \"a clean but forgettable game\", \"it was a close election\"],\n",
    "            'tag': [\"sports\", \"not_sports\", \"sports\", \"sports\", \"not_sports\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a great game</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the election was over</td>\n",
       "      <td>not_sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very clean match</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a clean but forgettable game</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it was a close election</td>\n",
       "      <td>not_sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           text         tag\n",
       "0                  a great game      sports\n",
       "1         the election was over  not_sports\n",
       "2              very clean match      sports\n",
       "3  a clean but forgettable game      sports\n",
       "4       it was a close election  not_sports"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = pd.DataFrame(word_dict)\n",
    "word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    a great game\n",
       "1           the election was over\n",
       "2                very clean match\n",
       "3    a clean but forgettable game\n",
       "4         it was a close election\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = word_df.iloc[:, 0]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        sports\n",
       "1    not_sports\n",
       "2        sports\n",
       "3        sports\n",
       "4    not_sports\n",
       "Name: tag, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = word_df.iloc[:, 1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.Series(['a very close game', \"the election was over\", 'game over match it'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.Series(['sports', 'not_sports', 'not_sports'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Dataframe\n",
    "Create sparse matrix of words in training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sparse matrix of words\n",
    "# input is dataframe of text\n",
    "\n",
    "def create_word_mat(df_docs_text):\n",
    "    # initialize empty list to store counts for each observation\n",
    "    word_dicts = []\n",
    "    \n",
    "    for doc in df_docs_text:\n",
    "        word_counts = {}\n",
    "        # split sentences into individual words\n",
    "        words = nltk.word_tokenize(doc)\n",
    "        # calc word counts for each word in observation\n",
    "        for word in words:\n",
    "            if word.isalnum():\n",
    "                if word in word_counts.values():\n",
    "                    word_counts[word] += 1\n",
    "                else:\n",
    "                    word_counts[word] = 1\n",
    "            else:\n",
    "                pass\n",
    "        # add word counts for observation to list\n",
    "        word_dicts.append(word_counts)\n",
    "    \n",
    "    # create dataframe of all observation word counts (0's fill empty word count cells)\n",
    "    df_words = pd.DataFrame.from_records(word_dicts).fillna(0)\n",
    "    return(df_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>but</th>\n",
       "      <th>clean</th>\n",
       "      <th>close</th>\n",
       "      <th>election</th>\n",
       "      <th>forgettable</th>\n",
       "      <th>game</th>\n",
       "      <th>great</th>\n",
       "      <th>it</th>\n",
       "      <th>match</th>\n",
       "      <th>over</th>\n",
       "      <th>the</th>\n",
       "      <th>very</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  but  clean  close  election  forgettable  game  great   it  match  \\\n",
       "0  1.0  0.0    0.0    0.0       0.0          0.0   1.0    1.0  0.0    0.0   \n",
       "1  0.0  0.0    0.0    0.0       1.0          0.0   0.0    0.0  0.0    0.0   \n",
       "2  0.0  0.0    1.0    0.0       0.0          0.0   0.0    0.0  0.0    1.0   \n",
       "3  1.0  1.0    1.0    0.0       0.0          1.0   1.0    0.0  0.0    0.0   \n",
       "4  1.0  0.0    0.0    1.0       1.0          0.0   0.0    0.0  1.0    0.0   \n",
       "\n",
       "   over  the  very  was  \n",
       "0   0.0  0.0   0.0  0.0  \n",
       "1   1.0  1.0   0.0  1.0  \n",
       "2   0.0  0.0   1.0  0.0  \n",
       "3   0.0  0.0   0.0  0.0  \n",
       "4   0.0  0.0   0.0  1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = create_word_mat(X)\n",
    "df_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Probabilities\n",
    "Calculate probabilities of each word per class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of nbayes\n",
    "model = NBayesClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>but</th>\n",
       "      <th>clean</th>\n",
       "      <th>close</th>\n",
       "      <th>election</th>\n",
       "      <th>forgettable</th>\n",
       "      <th>game</th>\n",
       "      <th>great</th>\n",
       "      <th>it</th>\n",
       "      <th>match</th>\n",
       "      <th>over</th>\n",
       "      <th>the</th>\n",
       "      <th>very</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_sports</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     a       but     clean     close  election  forgettable  \\\n",
       "class_labels                                                                  \n",
       "not_sports    0.086957  0.043478  0.043478  0.086957  0.130435     0.043478   \n",
       "sports        0.120000  0.080000  0.120000  0.040000  0.040000     0.080000   \n",
       "\n",
       "                  game     great        it     match      over       the  \\\n",
       "class_labels                                                               \n",
       "not_sports    0.043478  0.043478  0.086957  0.043478  0.086957  0.086957   \n",
       "sports        0.120000  0.080000  0.040000  0.080000  0.040000  0.040000   \n",
       "\n",
       "                  very       was  \n",
       "class_labels                      \n",
       "not_sports    0.043478  0.130435  \n",
       "sports        0.080000  0.040000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probas = model.calc_probas(df_words, y)\n",
    "df_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Predict class labels for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [a, very, close, game]\n",
       "1    [the, election, was, over]\n",
       "2       [game, over, match, it]\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-process test features\n",
    "words = X_test.apply(lambda x: nltk.word_tokenize(x))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        sports\n",
       "1    not_sports\n",
       "2        sports\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = model.predict_class(words)\n",
    "predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "Retrieve model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n"
     ]
    }
   ],
   "source": [
    "model.metrics(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
