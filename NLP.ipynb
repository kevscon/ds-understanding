{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    " \n",
    "stemmer = PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jumped'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatiser.lemmatize('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/spooky/train.csv')\n",
    "test = pd.read_csv('data/spooky/test.csv')\n",
    "sample = pd.read_csv('data/spooky/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       EAP       HPL       MWS\n",
       "0  id02310  0.403494  0.287808  0.308698\n",
       "1  id24541  0.403494  0.287808  0.308698\n",
       "2  id00134  0.403494  0.287808  0.308698\n",
       "3  id27757  0.403494  0.287808  0.308698\n",
       "4  id04081  0.403494  0.287808  0.308698"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This process, however, afforded me no means of...\n",
       "1    It never once occurred to me that the fumbling...\n",
       "2    In his left hand was a gold snuff box, from wh...\n",
       "3    How lovely is spring As we looked from Windsor...\n",
       "4    Finding nothing else, not even gold, the Super...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shuffle(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = nltk.WordNetLemmatizer()\n",
    "class LemmaCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the entire training text in a list\n",
    "text = list(train['text'].values)\n",
    "# Calling our overwritten Count vectorizer\n",
    "tf_cv_vec = LemmaCountVectorizer(max_df=0.95, \n",
    "                                     min_df=2,\n",
    "                                     stop_words='english',\n",
    "                                     decode_error='ignore')\n",
    "tf_cv = tf_cv_vec.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abaout</th>\n",
       "      <th>abate</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>...</th>\n",
       "      <th>zest</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zigzagging</th>\n",
       "      <th>zimmer</th>\n",
       "      <th>zit</th>\n",
       "      <th>zodiacal</th>\n",
       "      <th>zokkar</th>\n",
       "      <th>zone</th>\n",
       "      <th>ædile</th>\n",
       "      <th>æronaut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13781 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aback  abandon  abandoned  abandoning  abandonment  abaout  abate  \\\n",
       "0      0        0          0           0            0       0      0   \n",
       "1      0        0          0           0            0       0      0   \n",
       "2      0        0          0           0            0       0      0   \n",
       "3      0        0          0           0            0       0      0   \n",
       "4      0        0          0           0            0       0      0   \n",
       "\n",
       "   abatement  abbey  abbreviation   ...     zest  zigzag  zigzagging  zimmer  \\\n",
       "0          0      0             0   ...        0       0           0       0   \n",
       "1          0      0             0   ...        0       0           0       0   \n",
       "2          0      0             0   ...        0       0           0       0   \n",
       "3          0      0             0   ...        0       0           0       0   \n",
       "4          0      0             0   ...        0       0           0       0   \n",
       "\n",
       "   zit  zodiacal  zokkar  zone  ædile  æronaut  \n",
       "0    0         0       0     0      0        0  \n",
       "1    0         0       0     0      0        0  \n",
       "2    0         0       0     0      0        0  \n",
       "3    0         0       0     0      0        0  \n",
       "4    0         0       0     0      0        0  \n",
       "\n",
       "[5 rows x 13781 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cv_df = pd.DataFrame(tf_cv.toarray(), columns=tf_cv_vec.get_feature_names())\n",
    "tf_cv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(tf_cv_df, train['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_selection.cross_val_score(nb, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8187136295048398"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8177732379979571"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Class Probabilities for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the entire training text in a list\n",
    "text = list(test['text'].values)\n",
    "tf_cv = tf_cv_vec.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abaout</th>\n",
       "      <th>abate</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>...</th>\n",
       "      <th>zest</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zigzagging</th>\n",
       "      <th>zimmer</th>\n",
       "      <th>zit</th>\n",
       "      <th>zodiacal</th>\n",
       "      <th>zokkar</th>\n",
       "      <th>zone</th>\n",
       "      <th>ædile</th>\n",
       "      <th>æronaut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13781 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aback  abandon  abandoned  abandoning  abandonment  abaout  abate  \\\n",
       "0      0        0          0           0            0       0      0   \n",
       "1      0        0          0           0            0       0      0   \n",
       "2      0        0          0           0            0       0      0   \n",
       "3      0        0          0           0            0       0      0   \n",
       "4      0        0          0           0            0       0      0   \n",
       "\n",
       "   abatement  abbey  abbreviation   ...     zest  zigzag  zigzagging  zimmer  \\\n",
       "0          0      0             0   ...        0       0           0       0   \n",
       "1          0      0             0   ...        0       0           0       0   \n",
       "2          0      0             0   ...        0       0           0       0   \n",
       "3          0      0             0   ...        0       0           0       0   \n",
       "4          0      0             0   ...        0       0           0       0   \n",
       "\n",
       "   zit  zodiacal  zokkar  zone  ædile  æronaut  \n",
       "0    0         0       0     0      0        0  \n",
       "1    0         0       0     0      0        0  \n",
       "2    0         0       0     0      0        0  \n",
       "3    0         0       0     0      0        0  \n",
       "4    0         0       0     0      0        0  \n",
       "\n",
       "[5 rows x 13781 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cv_df = pd.DataFrame(tf_cv.toarray(), columns=tf_cv_vec.get_feature_names())\n",
    "tf_cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = nb.predict_proba(tf_cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EAP', 'HPL', 'MWS'], dtype='<U3')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>0.016745</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>9.815623e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.452599e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>0.786284</td>\n",
       "      <td>0.213639</td>\n",
       "      <td>7.724627e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>0.072432</td>\n",
       "      <td>0.927567</td>\n",
       "      <td>9.328623e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>0.954378</td>\n",
       "      <td>0.027604</td>\n",
       "      <td>1.801725e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EAP       HPL           MWS\n",
       "id                                       \n",
       "id02310  0.016745  0.001693  9.815623e-01\n",
       "id24541  0.999976  0.000010  1.452599e-05\n",
       "id00134  0.786284  0.213639  7.724627e-05\n",
       "id27757  0.072432  0.927567  9.328623e-07\n",
       "id04081  0.954378  0.027604  1.801725e-02"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_df = pd.DataFrame(predicts, index=test['id'], columns=nb.classes_)\n",
    "pred_proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id02310    MWS\n",
       "id24541    EAP\n",
       "id00134    EAP\n",
       "id27757    HPL\n",
       "id04081    EAP\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_preds = pred_proba_df.idxmax(axis=1)\n",
    "auth_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = nltk.WordNetLemmatizer()\n",
    "class LemmaCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the entire training text in a list\n",
    "text = list(train['text'].values)\n",
    "# Calling our overwritten Count vectorizer\n",
    "tf_df_vec = TfidfVectorizer(max_df=0.95, \n",
    "                                min_df=2,\n",
    "                                stop_words='english')\n",
    "tf_df = tf_df_vec.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abaout</th>\n",
       "      <th>abate</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>...</th>\n",
       "      <th>zest</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zigzagging</th>\n",
       "      <th>zimmer</th>\n",
       "      <th>zit</th>\n",
       "      <th>zodiacal</th>\n",
       "      <th>zokkar</th>\n",
       "      <th>zone</th>\n",
       "      <th>ædile</th>\n",
       "      <th>æronaut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 15378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aback  abandon  abandoned  abandoning  abandonment  abaout  abate  \\\n",
       "0    0.0      0.0        0.0         0.0          0.0     0.0    0.0   \n",
       "1    0.0      0.0        0.0         0.0          0.0     0.0    0.0   \n",
       "2    0.0      0.0        0.0         0.0          0.0     0.0    0.0   \n",
       "3    0.0      0.0        0.0         0.0          0.0     0.0    0.0   \n",
       "4    0.0      0.0        0.0         0.0          0.0     0.0    0.0   \n",
       "\n",
       "   abatement  abbey  abbreviation   ...     zest  zigzag  zigzagging  zimmer  \\\n",
       "0        0.0    0.0           0.0   ...      0.0     0.0         0.0     0.0   \n",
       "1        0.0    0.0           0.0   ...      0.0     0.0         0.0     0.0   \n",
       "2        0.0    0.0           0.0   ...      0.0     0.0         0.0     0.0   \n",
       "3        0.0    0.0           0.0   ...      0.0     0.0         0.0     0.0   \n",
       "4        0.0    0.0           0.0   ...      0.0     0.0         0.0     0.0   \n",
       "\n",
       "   zit  zodiacal  zokkar  zone  ædile  æronaut  \n",
       "0  0.0       0.0     0.0   0.0    0.0      0.0  \n",
       "1  0.0       0.0     0.0   0.0    0.0      0.0  \n",
       "2  0.0       0.0     0.0   0.0    0.0      0.0  \n",
       "3  0.0       0.0     0.0   0.0    0.0      0.0  \n",
       "4  0.0       0.0     0.0   0.0    0.0      0.0  \n",
       "\n",
       "[5 rows x 15378 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df_df = pd.DataFrame(tf_df.toarray(), columns=tf_df_vec.get_feature_names())\n",
    "tf_df_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tf_df_df, train['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_selection.cross_val_score(nb, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8140128476274281"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.820020429009193"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap = train[train['author'] == 'EAP']['text']\n",
    "hpl = train[train['author'] == 'HPL']['text']\n",
    "mws = train[train['author'] == 'MWS']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print top words\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        message = \"\\nTopic #{}:\".format(index)\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1 :-1]])\n",
    "        print(message)\n",
    "        print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=11, max_iter=5,\n",
    "                                learning_method = 'online',\n",
    "                                learning_offset = 50.,\n",
    "                                random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=11, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(tf_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model (using CountVectorizer): \n",
      "\n",
      "Topic #0:mean night fact young return great human looking wonder countenance difficulty greater wife finally set possessed regard struck perceived act society law health key fearful mr exceedingly evidence carried home write lady various recall accident force poet neck conduct investigation\n",
      "======================================================================\n",
      "\n",
      "Topic #1:death love raymond hope heart word child went time good man ground evil long misery replied filled passion bed till happiness memory heavy region year escape spirit grief visit doe story beauty die plague making influence thou letter appeared power\n",
      "======================================================================\n",
      "\n",
      "Topic #2:left let hand said took say little length body air secret gave right having great arm thousand character minute foot true self gentleman pleasure box clock discovered point sought pain nearly case best mere course manner balloon fear head going\n",
      "======================================================================\n",
      "\n",
      "Topic #3:called sense table suddenly sympathy machine sens unusual labour thrown mist solution suppose specie movement whispered urged frequent wine hour appears ring turk place stage noon justine ceased obscure chair completely exist sitting supply weird bottle seated drink material bell\n",
      "======================================================================\n",
      "\n",
      "Topic #4:house man old soon city room sight did believe mr light entered sir cloud order ill way dr apparently clear certain forgotten day quite door considered need great fine began journey search walked disposition view long concerning walk drawn saw\n",
      "======================================================================\n",
      "\n",
      "Topic #5:thing thought eye mind said men night like face life head dream knew saw form world away deep stone told matter morning perdita dead general man strange seen terrible sleep tell object tear know account better black say remained little\n",
      "======================================================================\n",
      "\n",
      "Topic #6:father moon stood longer attention end sure leave remember time excited period trace dream given star place able grew subject set cut visited captain consequence marie taking forward started descent atmosphere impulse departure dog men truly abyss appear magnificent quarter\n",
      "======================================================================\n",
      "\n",
      "Topic #7:day did heard life time friend new far horror nature come look tree year present soul passed known people heart felt degree scene idea hand feeling world came country adrian moment make word affection sun gone reached idris youth seen\n",
      "======================================================================\n",
      "\n",
      "Topic #8:came earth street near like sound wall window just open lay fell wind looked saw moment water eye dark spirit beneath mountain old did light foot long town space floor low happy held half voice living direction ear small end\n",
      "======================================================================\n",
      "\n",
      "Topic #9:shall place sea time think long fear know mother day person say brought expression land change question night result ye week mad month feel god rest got manner course horrible large resolved kind passage far discovery word answer eye ago\n",
      "======================================================================\n",
      "\n",
      "Topic #10:door turned close away design view doubt ordinary tried oh madness room enemy le lower exertion chamber opening candle legend occupation abode lofty author compartment breath flame accursed machinery horse iron proceeded curse ve louder desired entering appeared lock oil\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 40\n",
    "print(\"\\nTopics in LDA model (using CountVectorizer): \")\n",
    "tf_feature_names = tf_cv_vec.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=11, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(tf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model (using TFIDF): \n",
      "\n",
      "Topic #0:agreed locked hotel captain la enemies dignity disappearance france et propose bird routine shutters sheehan trying accomplishment pillars securely sorrowful cohort justly calls recover hesitate traversed exhibiter defeat obeyed nodded community stamp preceded personally nice pratt cape steadied fruiterer clerk\n",
      "======================================================================\n",
      "\n",
      "Topic #1:write usually accomplished suggestion plainly powerful demand notwithstanding editor te oppodeldoc passages expedition dominion neat lollipop deity hurt communicated thomas vainly ugly kill arrangement necessity drama intend happier conquer lawless survive agreeable alas tangible harmless du induce fragment identical infirmity\n",
      "======================================================================\n",
      "\n",
      "Topic #2:profound safe von joe steady daown aout visits gang em ate est cutting gawd guests couch portrait burn gradual newspapers bushes struggling draught merciful beg background ether precipitated hatheg ascertain sweep development arrives glassy deposes empire started consumed scarlet entertain\n",
      "======================================================================\n",
      "\n",
      "Topic #3:thou thy noise mortal stairs diddler glorious frightened proceed crowded wonderful opinions coffin ellison ruins gathered expect substance exception restore try directly birch windows abysses leaned deceased injury jest ingenuity principal heh rule violet abaout glare moonlight waste bas aira\n",
      "======================================================================\n",
      "\n",
      "Topic #4:man time did life night said eyes old day long shall saw heart came death thought like love great years mind little felt know come raymond world father earth things men heard say away knew light words friend place fear\n",
      "======================================================================\n",
      "\n",
      "Topic #5:ve motions affected universal wants hospital pen price risen dancing shrieks burthen agonizing contest hat syllable helpless worlds appeal blush roll extract puff pace fits windings repulsive groans tobey reap blazing gum funny impediment stillness summits yxu vigor flitted gifted\n",
      "======================================================================\n",
      "\n",
      "Topic #6:money surely poet meant rare cease destroyed particulars saved limb remove obviously won sum failure entertained principles partially flames fastened resistance shrank receiving provided security pit belonged gesture proposed sincerely pulled project welcomed partial drank helped stumbled charnel modes celebrated\n",
      "======================================================================\n",
      "\n",
      "Topic #7:supreme crew follows converse cthulhu zadok somebody orders fainting submit harsh bandage wealthy deformity tea combat extravagant wrist pot respite interruption collect throats parliament visiting schools offering stooping frequented perversion modesty rowena warmest vigour wronged paralysed complacency tenement siege energies\n",
      "======================================================================\n",
      "\n",
      "Topic #8:unusual useless choice ha rushing wilson freely hesitated recognised grace pray murmur softly robe arising occasional sword respects intellectual variation newly consisted measures mademoiselle sorrows travelled usher roused damned rudder perish prepare fires sufferer duke ourang duc berenice marshes comfort\n",
      "======================================================================\n",
      "\n",
      "Topic #9:escape answer said henry smith season contents extended cases variety observations dupin john pull grandfather comprehend alfred introduced dreary martense fifth perpetually trever error pretend general remembrance normal pay disgust lighted decidedly supposition wherefore apply glimpsed travelling happen troops beasts\n",
      "======================================================================\n",
      "\n",
      "Topic #10:said water door say little word thing did left matter time room saw lady body seen old house england like length great right feet man mean case far box corpse uncle way course use later beautiful simple ye point design\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 40\n",
    "print(\"\\nTopics in LDA model (using TFIDF): \")\n",
    "tf_feature_names = tf_df_vec.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = lda.components_[0]\n",
    "second_topic = lda.components_[1]\n",
    "third_topic = lda.components_[2]\n",
    "fourth_topic = lda.components_[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic_words = [tf_feature_names[i] for i in first_topic.argsort()[:-50 - 1 :-1]]\n",
    "second_topic_words = [tf_feature_names[i] for i in second_topic.argsort()[:-50 - 1 :-1]]\n",
    "third_topic_words = [tf_feature_names[i] for i in third_topic.argsort()[:-50 - 1 :-1]]\n",
    "fourth_topic_words = [tf_feature_names[i] for i in fourth_topic.argsort()[:-50 - 1 :-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=11, max_iter=5,\n",
    "                                random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=5,\n",
       "  n_components=11, random_state=0, shuffle=False, solver='cd', tol=0.0001,\n",
       "  verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.fit(tf_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model: \n",
      "\n",
      "Topic #0:great word earth mind saw world thought felt deep love sea heard beauty evil spirit feeling scene shall light away good lovely god came multitude far form wisdom appeared wind oh nature voice near diotima moon human men lip say\n",
      "======================================================================\n",
      "\n",
      "Topic #1:time long hour come year thousand space short thought friend place matter way say make moment period new soon mean fear shall certain body foot room lost point length far line having second spent manner course memory idea grief person\n",
      "======================================================================\n",
      "\n",
      "Topic #2:man old god young farewell mr nature seen woman face power dark work good terrible human small animal tell city believe bearded way say sir person business water air sound long wonder set blind form general came high book dr\n",
      "======================================================================\n",
      "\n",
      "Topic #3:day night hour came passed long dream new far away sleep thousand month sun morning men mr late room having city went father work period week hill body house told year dark following home let raymond grew early place thought\n",
      "======================================================================\n",
      "\n",
      "Topic #4:thing say men strange night old house told know knew window terrible street living small world way dead place sort horror seen let dream matter door earth room ancient fear book state fact half unknown tell odd stone folk sea\n",
      "======================================================================\n",
      "\n",
      "Topic #5:said shall say know thousand friend come little mr dupin let sure sir thought pound dear great make matter von raymond yes word ha took voice just ugh gentleman adrian mean good speak best father watch smith monsieur bob way\n",
      "======================================================================\n",
      "\n",
      "Topic #6:little hand eye left head door face room open long right arm foot voice wall length light window turned half black small place away took fell having lay saw floor moment gave body far large near street sat table stood\n",
      "======================================================================\n",
      "\n",
      "Topic #7:did house night say door came room mr place come believe long understand thought fail feel course window hour look sound appear way know wish knew street heard return reason think end make certain west wall point attempt circumstance step\n",
      "======================================================================\n",
      "\n",
      "Topic #8:eye heart know soul love beauty end ye oh study tear heaven think misery teach universe knowledge shall fixed secret hope true affection ought despair posse expression make look star conclusion acquainted unfolded mind universal nature thou delight step silence\n",
      "======================================================================\n",
      "\n",
      "Topic #9:like came looked long say water human light look sound mr spirit ye foot head black white face big vast strange cloud em wall small tree form way daown thousand place sleep dead folk dream ah gold high wind voice\n",
      "======================================================================\n",
      "\n",
      "Topic #10:life old year death house father hope heart child friend age mother passed new dream lost dead street told century young place tear happiness men raymond existence family book ago die having change youth happy joy people nature month hour\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 40\n",
    "print(\"\\nTopics in NMF model: \")\n",
    "tf_feature_names = tf_cv_vec.get_feature_names()\n",
    "print_top_words(nmf, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=5,\n",
       "  n_components=11, random_state=0, shuffle=False, solver='cd', tol=0.0001,\n",
       "  verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.fit(tf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model: \n",
      "\n",
      "Topic #0:life like eyes death heart great mind thought left years world felt things earth long far little men love father hand words place human friend good nature soon head moment house having length away strange voice raymond old gave half\n",
      "======================================================================\n",
      "\n",
      "Topic #1:said dupin little let sir yes dear heard better quite mean friend thousand proceed sure come present pounds matter father words raymond adrian somebody enjoy prefect tone big paper legrand talk great smith coming second fool reply comprehend pardon turning\n",
      "======================================================================\n",
      "\n",
      "Topic #2:did come like appear perdita understand return expected believe fail fear look expect feel knew write despair dark proceed pass best sleep change looked mean dare tell pay wish prove forgotten companion reason grew asked occur west saying dogs thief\n",
      "======================================================================\n",
      "\n",
      "Topic #3:man old great young god seen dead animal lived absent woman face bearded sat business terrible good sir respect blind small feared fool spoke reason loved room creation follow poet years genius ordinary nature ones fred lacey work cottage believe\n",
      "======================================================================\n",
      "\n",
      "Topic #4:say shall let course lost needless general dare truth reason precisely scarcely strange die make object mind impossible think speak believe point true questioned just matter reward come difficult explain don conduct suspicion happy idea mean present god wrong seen\n",
      "======================================================================\n",
      "\n",
      "Topic #5:came night heard door house room sleep moon went morning seen light street window open dark passed sounds just knew men home away wind sound people slept chamber hours outside windows darkness sea opened evening retired rain told ears till\n",
      "======================================================================\n",
      "\n",
      "Topic #6:time long mean short spent hour space think years place come hours raymond friends home return greece lived year elapsed lose lord reached ago remained moment room house happy experience continued new care innsmouth matter certain length hoped occupied grief\n",
      "======================================================================\n",
      "\n",
      "Topic #7:day night shall passed come morrow return grew sun hour following late arrived raymond sunday occurred continued present death slept noon called weaker melancholy year till dream new home resolved week feelings away commenced spent hope sleep occupied live dawned\n",
      "======================================================================\n",
      "\n",
      "Topic #8:know knew things don believe tell little fact think matter right strange really ye sure wants gentleman make old mistaken mean reply place shall world whispered gone books feel shouldn political certain happened does took ll good secret escaped ought\n",
      "======================================================================\n",
      "\n",
      "Topic #9:saw felt looked eyes heard change suddenly stood moon face far room light black position beheld lips knew stated lights shore form window wall waves went fear length glow rowena waters thought looking sky city reply need floor windows horror\n",
      "======================================================================\n",
      "\n",
      "Topic #10:thing let little thought love eyes impossible going yes simple unknown easily terrible ve curious proved just living tell similar seen occurred profound obvious world funny investigation style method horror somewhat pretty laboratory sort furry peculiar try annoyed particular stands\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 40\n",
    "print(\"\\nTopics in NMF model: \")\n",
    "tf_feature_names = tf_df_vec.get_feature_names()\n",
    "print_top_words(nmf, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = nmf_model.components_[0]\n",
    "second_topic = nmf_model.components_[1]\n",
    "third_topic = nmf_model.components_[2]\n",
    "fourth_topic = nmf_model.components_[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic_words_nmf = [tf_feature_names[i] for i in first_topic.argsort()[:-50 - 1 :-1]]\n",
    "second_topic_words_nmf = [tf_feature_names[i] for i in second_topic.argsort()[:-50 - 1 :-1]]\n",
    "third_topic_words_nmf = [tf_feature_names[i] for i in third_topic.argsort()[:-50 - 1 :-1]]\n",
    "fourth_topic_words_nmf = [tf_feature_names[i] for i in fourth_topic.argsort()[:-50 - 1 :-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shuffle data\n",
    "- kfold validation\n",
    "- additional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- determine optimal number of topics (k-means?)\n",
    "- select best topics\n",
    "- match back to author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
